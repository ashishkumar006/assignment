# Compact MNIST Classifier ğŸš€

[![Build Status](https://github.com/ashishkumar006/assignment/actions/workflows/model_test.yml/badge.svg)](https://github.com/ashishkumar006/assignment/actions/workflows/model_test.yml)
[![Python 3.8](https://img.shields.io/badge/python-3.8-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.10.0-EE4C2C.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A lightweight PyTorch implementation of an MNIST classifier achieving **98.62%** accuracy in a single epoch with fewer than 25,000 parameters. Designed for efficiency and reproducibility.

## ğŸ¯ Model Performance

| Metric | Value 
|--------|-------
| Parameters | 19,570 
| Training Accuracy | 95.80% 
| Test Accuracy | 98.62% 
| Training Time | 1 epoch 

## ğŸ“¦ Requirements

```bash
torch==1.10.0+cpu
torchvision
numpy
tqdm
pytest
```

## ğŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/ashishkumar006/assignment.git
cd assignment

# Install dependencies
pip install -r requirements.txt

# Train and evaluate model
python train.py

# Run tests
pytest tests/
```

## ğŸ” Testing Strategy

- âœ… Automated testing via GitHub Actions
- ğŸ“Š Parameter count verification (<25,000)
- ğŸ“ˆ Accuracy threshold verification (>95%)
- ğŸ² Deterministic training with fixed seeds
- ğŸ’» CPU-compatible implementation

## ğŸ—ï¸ Model Architecture

- ğŸ§  Compact CNN design
- âš¡ Efficient parameter utilization
- ğŸ”„ Residual connections
- ğŸ¯ Optimized for single-epoch training

## âš™ï¸ Implementation Details

- ğŸ“ˆ AdamW optimizer
- ğŸ“‰ Learning rate scheduling
- ğŸ”— Gradient clipping
- ğŸ² Deterministic training
- ğŸ–¼ï¸ No data augmentation

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“Š Performance Visualization

```
Training Progress:
[====================] 100%
Final Accuracy: 98.62%
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“« Contact

If you have any questions, feel free to open an issue or reach out directly.